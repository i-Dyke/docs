import { Callout } from 'nextra/components'

<Callout type="warning" emoji="⚠️">
This documentation is under construction and incomplete. Please [sign up here for K-Scale updates](https://forms.gle/xkba4WWGD5Pmayj96) and check back later for our progress.
</Callout>

## Minimal PPO Implementation

[GitHub](https://github.com/kscalelabs/minppo)

A minimal implementation of Proximal Policy Optimization (PPO) utilizing JAX in just three files. Users can import their own custom Mujoco environemnts, define their rewards, and train their own agents with ease.

With this pipeline, we can train agents to perform basic tasks with complete understanding of the underlying training loop, rewards, and physics. Compared to Isaac Gym, this pipeline is much more easier to understand, lightweight, and therefore hackable for research settings.

Here's a video with some basic walking/standing with a humanoid robot:

<iframe
    src="https://www.youtube.com/embed/Y-mD7Cp9KSs"
    title="MinPPO Demo"
    frameBorder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    style={{ width: '100%', aspectRatio: '16/9', marginTop: '2rem' }}
    allowFullScreen
/>
